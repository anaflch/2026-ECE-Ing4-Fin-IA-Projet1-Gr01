Scoring de crÃ©dit Ã©quitable par optimisation sous contraintes

1. Contexte et objectif du projet

Les systÃ¨mes de scoring de crÃ©dit sont aujourdâ€™hui largement automatisÃ©s Ã  lâ€™aide de modÃ¨les de machine learning.
Cependant, ces modÃ¨les peuvent reproduire ou amplifier des biais discriminatoires prÃ©sents dans les donnÃ©es historiques, en dÃ©favorisant certains groupes (par exemple selon le sexe ou la nationalitÃ©).

Lâ€™objectif de ce projet est de :

Concevoir un systÃ¨me dâ€™intelligence artificielle de scoring de crÃ©dit intÃ©grant explicitement des contraintes dâ€™Ã©quitÃ©, afin de contrÃ´ler et quantifier le compromis entre performance prÃ©dictive et non-discrimination.

â¸»

2. ProblÃ©matique Ã©tudiÃ©e

Le projet rÃ©pond Ã  la question suivante :

Comment intÃ©grer formellement des contraintes dâ€™Ã©quitÃ© dans un modÃ¨le de scoring de crÃ©dit, tout en conservant des performances prÃ©dictives acceptables ?

Pour cela, le problÃ¨me est formulÃ© comme une optimisation sous contraintes, oÃ¹ les mÃ©triques dâ€™Ã©quitÃ© (Demographic Parity, Equalized Odds) sont imposÃ©es directement lors de lâ€™apprentissage du modÃ¨le.

â¸»

3. Jeu de donnÃ©es

Le projet utilise un jeu de donnÃ©es clients rÃ©aliste (clients.csv) contenant :

ğŸ”¹ Variable cible
	â€¢	default : dÃ©faut de paiement (0 = non, 1 = oui)

ğŸ”¹ Attribut sensible
	â€¢	sex : utilisÃ© pour mesurer et contraindre lâ€™Ã©quitÃ© du modÃ¨le

ğŸ”¹ Variables explicatives
	â€¢	DonnÃ©es financiÃ¨res : income, credit_amount, loan_duration
	â€¢	StabilitÃ© professionnelle : employment_years
	â€¢	Situation personnelle : marital_status, housing_status, dependents
	â€¢	Niveau dâ€™Ã©ducation : education_level

La colonne name est supprimÃ©e lors du prÃ©-traitement car elle ne contient aucune information utile pour la prÃ©diction.

FCC/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py           # Configuration (chemins, colonnes)
â”‚   â”œâ”€â”€ preprocessing.py    # PrÃ©-traitement des donnÃ©es
â”‚   â”œâ”€â”€ models.py           # ModÃ¨les ML de base
â”‚   â”œâ”€â”€ fairness.py         # Contraintes dâ€™Ã©quitÃ© (Fairlearn)
â”‚   â”œâ”€â”€ evaluate.py         # MÃ©triques de performance et dâ€™Ã©quitÃ©
â”‚   â”œâ”€â”€ explain.py          # ExplicabilitÃ© (SHAP)
â”‚   â”œâ”€â”€ main.py             # Point dâ€™entrÃ©e du projet
â”‚   â””â”€â”€ plot_results.py     # GÃ©nÃ©ration des graphiques
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/clients.csv
â”‚   â””â”€â”€ processed/results.json
â””â”€â”€ requirements.txt

5. Approche mÃ©thodologique

5.1 ModÃ¨le de base (baseline)

Un modÃ¨le de rÃ©gression logistique est entraÃ®nÃ© sans contrainte dâ€™Ã©quitÃ©.

Objectif :
	â€¢	Maximiser la performance prÃ©dictive (accuracy, AUC)
	â€¢	Servir de point de comparaison

Ce modÃ¨le est performant, mais prÃ©sente des diffÃ©rences de traitement entre groupes.

â¸»

5.2 Mesure de lâ€™Ã©quitÃ©

Les mÃ©triques suivantes sont utilisÃ©es :
	â€¢	Demographic Parity Difference (DP)
DiffÃ©rence de taux dâ€™acceptation entre groupes
	â€¢	Equalized Odds Difference (EO)
DiffÃ©rence de faux positifs et faux nÃ©gatifs entre groupes

Ces mÃ©triques permettent de quantifier objectivement la discrimination du modÃ¨le.

â¸»

5.3 ModÃ¨les Ã©quitables (in-processing)

Lâ€™Ã©quitÃ© est intÃ©grÃ©e directement dans lâ€™apprentissage grÃ¢ce Ã  la librairie Fairlearn, via lâ€™algorithme :
	â€¢	Exponentiated Gradient Reduction

Deux contraintes sont Ã©tudiÃ©es :
	â€¢	Demographic Parity
	â€¢	Equalized Odds

Le paramÃ¨tre epsilon contrÃ´le le niveau de tolÃ©rance Ã  la violation de lâ€™Ã©quitÃ©.

â¸»

5.4 Analyse du compromis Ã©quitÃ© / performance

Le projet fait varier epsilon afin dâ€™observer :
	â€¢	la rÃ©duction progressive des biais
	â€¢	lâ€™impact sur la performance prÃ©dictive

Cette analyse permet de montrer que lâ€™Ã©quitÃ© est un choix de gouvernance, et non une propriÃ©tÃ© binaire.

â¸»

6. RÃ©sultats principaux

Un fichier results.json est gÃ©nÃ©rÃ© automatiquement et contient :
	â€¢	performances (accuracy, AUC)
	â€¢	mÃ©triques dâ€™Ã©quitÃ© (dp_diff, eo_diff)
	â€¢	mÃ©triques par groupe

Des graphiques sont produits :
	â€¢	Trade-off AUC vs epsilon
	â€¢	Trade-off Demographic Parity vs epsilon
	â€¢	Taux dâ€™acceptation par groupe (baseline vs modÃ¨les Ã©quitables)

ğŸ” Observation clÃ©
	â€¢	Le modÃ¨le de base est le plus performant mais le plus discriminant
	â€¢	Les modÃ¨les Ã©quitables rÃ©duisent fortement les biais
	â€¢	La perte de performance reste modÃ©rÃ©e et contrÃ´lable

â¸»
8. Installation et exÃ©cution

CrÃ©ation de lâ€™environnement virtuel :
    python3 -m venv .venv
    source .venv/bin/activate

Installation des dÃ©pendances :
    pip install -r FCC/requirements.txt

Lancement du projet :
    python -m FCC.src.main

GÃ©nÃ©ration des graphiques :
    python -m FCC.src.plot_results

---

## ğŸ‘¥ Ã‰quipe
- **Hugo**
- **Jeremy**
- **Mael**

Projet rÃ©alisÃ© dans le cadre du cours *Intelligence Artificielle â€“ Finance*
(ECE Paris, IngÃ©nieur 4áµ‰ annÃ©e).
